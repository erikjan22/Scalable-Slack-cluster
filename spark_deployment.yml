- hosts: all
  tasks:

   - name: Generate hosts file
     lineinfile: dest=/etc/hosts
                 regexp='.*{{ item }}$'
                 line="{{ hostvars[item].ansible_default_ipv4.address }} {{item}}"
                 state=present            
     when: hostvars[item].ansible_default_ipv4.address is defined
     with_items: "{{groups['all']}}"

   - name: Include variables
     include_vars: setup_var.yml
   
   - name: Set hostname
     hostname: name="{{inventory_hostname}}" 

   - name: apt update
     apt: update_cache=yes upgrade=dist

   - name: check whether spark exists
     stat:
       path: "{{spark_home}}"
     register: stat_result
 
   - name: download spark in case it does not exist
     unarchive: src={{item}} dest=/usr/local/ copy=no
     with_items: "{{spark_urls}}"
     when: stat_result.stat.exists == False

   - name: install java
     apt: 
       pkg: ['default-jre', 'default-jdk']
       state: present
       update_cache: true

   - name: adding paths
     lineinfile: dest="{{rc_file}}" line='export PATH=$PATH:{{spark_home}}/bin/:{{scala_home}}/bin\nexport JAVA_HOME={{java_home}}\nSPARK_HOME={{spark_home}}' insertafter='EOF' regexp='export PATH=\$SPARK_HOME' state=present 
   
   - name: source bashrc   
     shell: . "{{rc_file}}"


- hosts: sparkmaster
  
  vars_files:
   - setup_var.yml  

  tasks:
   - name: install jupyter
     apt:
       pkg: ['python-pip', 'python-dev', 'build-essential', 'python3-pip']
       state: present
       update_cache: true
 
   - pip: name=pip state=latest

   - pip: name=jupyter state=present
    
   - name: adding paths
     lineinfile: dest={{rc_file}} line='export JUPYTER_CONFIG_DIR={{jupyter_config_dir}}\n export JUPYTER_PATH={{jupyter_path}}\nexport JUPYTER_RUNTIME_DIR={{jupyter_runtime_dir}}' insertafter='EOF' regexp='export JUPYTER_PATH' state=present 

   - name: source bashrc   
     shell: . {{rc_file}}

   - name: start jupyter
     shell: runuser -l "{{username}}" -c 'jupyter notebook --ip=0.0.0.0 --port=60060 &'
     async: 2592000               # 60*60*24*30 â€“ 1 month
     args:
      executable: /bin/bash 
   
   - name: jupyter server token
     shell: cat /home/"{{username}}"/.local/share/jupyter/runtime/*.json | grep token
     register: token

   - debug:
      var: token.stdout_lines
   
   - name: disable IPv6
     shell: "{{item}}"
     with_items: 
      - echo "net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1" >> /etc/sysctl.conf
      - sysctl -p

   - name: start spark master process
     shell: nohup {{spark_home}}/sbin/start-master.sh &

   - name: start spark worker process
     shell: nohup {{spark_home}}/sbin/start-slave.sh spark://sparkmaster:7077 &


- hosts: all
  tasks:
  - name: wait for one second
    shell: sleep 1s

- hosts: sparkworker
    
  vars_files:
   - setup_var.yml

  tasks:
   - name: disable IPv6
     shell: "{{item}}"
     with_items:
      - echo "net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1" >> /etc/sysctl.conf
      - sysctl -p
 
   - name: start spark worker process
     shell: nohup {{spark_home}}/sbin/start-slave.sh spark://sparkmaster:7077 &
